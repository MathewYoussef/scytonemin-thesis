{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 · Σ Occupancy → Chromatogram Total (mg·gDW⁻¹)\n",
    "\n",
    "Recreate the mapping between reflectance Σ-occupancy and chromatogram-derived total scytonemin \n",
    "outlined in Figures 12–13 of the thesis. We recompute occupancies from the denoised spectra, \n",
    "aggregate by dose, join with the trimmed-dose concentrations, and fit linear models. The control \n",
    "dose (dose_1) is excluded as documented in the manuscript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "- `data/reference/mamba_ssm/denoised_full_run.csv` — denoised reflectance spectra.\n",
    "- `data/reference/reflectance/wavelength_grid.npy` — wavelength grid (300–600 nm).\n",
    "- `data/raw/initial_calibration/DAD_to_Concentration_AUC/treatments_corrected_amounts.csv` — per-sample mg·gDW⁻¹ totals.\n",
    "- `data/reference/initial_calibration/sample_id_truth.csv` — mapping sample → treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "REFLECTANCE_DIR = PROJECT_ROOT / 'data' / 'reference' / 'reflectance'\n",
    "MAMBA_REF_DIR = PROJECT_ROOT / 'data' / 'reference' / 'mamba_ssm'\n",
    "STAGE_DIR = PROJECT_ROOT / 'data' / 'raw' / 'initial_calibration' / 'DAD_to_Concentration_AUC'\n",
    "TRUTH_PATH = PROJECT_ROOT / 'data' / 'reference' / 'initial_calibration' / 'sample_id_truth.csv'\n",
    "\n",
    "sns.set_theme(style='whitegrid', context='talk')\n",
    "(REFLECTANCE_DIR / 'wavelength_grid.npy', MAMBA_REF_DIR / 'denoised_full_run.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths = np.load(REFLECTANCE_DIR / 'wavelength_grid.npy')\n",
    "denoised = pd.read_csv(MAMBA_REF_DIR / 'denoised_full_run.csv')\n",
    "amounts = pd.read_csv(STAGE_DIR / 'treatments_corrected_amounts.csv')\n",
    "truth = pd.read_csv(TRUTH_PATH)\n",
    "\n",
    "wavelength_cols = [col for col in denoised.columns if col.startswith('reflectance_nm_')]\n",
    "numeric_wavelengths = np.array([float(col.split('_')[-1]) for col in wavelength_cols])\n",
    "denoised[['relative_path'] + wavelength_cols[:3]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuum Removal + Occupancy (reuse from notebook 05)\n",
    "We reuse the helper functions from the earlier notebook to compute Σ occupancies for each ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuum_removed(signal: np.ndarray, lam: np.ndarray) -> np.ndarray:\n",
    "    lam_min, lam_max = lam[0], lam[-1]\n",
    "    baseline = signal[0] + (signal[-1] - signal[0]) * (lam - lam_min) / (lam_max - lam_min)\n",
    "    cr = baseline - signal\n",
    "    return np.clip(cr, 0, None)\n",
    "\n",
    "def bowl_template(lam: np.ndarray, amplitude: float) -> np.ndarray:\n",
    "    lam_min, lam_max = lam[0], lam[-1]\n",
    "    lam_center = 0.5 * (lam_min + lam_max)\n",
    "    halfwidth = 0.5 * (lam_max - lam_min)\n",
    "    lam_norm = (lam - lam_center) / halfwidth\n",
    "    bowl = amplitude * np.clip(1 - lam_norm**2, 0, None)\n",
    "    return bowl\n",
    "\n",
    "def occupancy_ratio(signal: np.ndarray, lam: np.ndarray) -> float:\n",
    "    cr = continuum_removed(signal, lam)\n",
    "    if cr.max() <= 0:\n",
    "        return 0.0\n",
    "    bowl = bowl_template(lam, cr.max())\n",
    "    numerator = np.trapz(cr, lam)\n",
    "    denominator = np.trapz(bowl, lam)\n",
    "    if denominator <= 0:\n",
    "        return 0.0\n",
    "    return float(np.clip(numerator / denominator, 0, 1))\n",
    "\n",
    "WINDOWS = {\n",
    "    'occ_320_480': (320.0, 480.0),\n",
    "    'occ_360_410': (360.0, 410.0),\n",
    "}\n",
    "\n",
    "def compute_occupancy_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    records = []\n",
    "    for idx, row in df.iterrows():\n",
    "        lam = numeric_wavelengths\n",
    "        signal = row[wavelength_cols].to_numpy(dtype=float)\n",
    "        entry = {'relative_path': row['relative_path']}\n",
    "        for label, (lam_min, lam_max) in WINDOWS.items():\n",
    "            mask = (lam >= lam_min) & (lam <= lam_max)\n",
    "            entry[label] = occupancy_ratio(signal[mask], lam[mask])\n",
    "        records.append(entry)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "occupancies = compute_occupancy_table(denoised)\n",
    "occupancies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Group IDs\n",
    "Group ID = treatment/sample/angle. We aggregate Σ occupancy by group, then by dose (Σ across orientations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_to_group(rel_path: str) -> str:\n",
    "    parts = rel_path.split('/')\n",
    "    return '/'.join(parts[:3])  # treatment_x/sample_y/angle\n",
    "\n",
    "occupancies['group_id'] = occupancies['relative_path'].map(relative_to_group)\n",
    "occupancies['dose'] = occupancies['group_id'].apply(lambda g: int(re.search(r'treatment_(\\d+)', g).group(1)))\n",
    "occupancies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sigma = occupancies.groupby(['dose'])[['occ_320_480', 'occ_360_410']].mean().reset_index()\n",
    "group_sigma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimmed Mean Concentrations (reuse trimmed mean from notebook 07)\n",
    "We compute 20% trimmed means per dose for the chromatogram total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treatment_order(labels) -> list:\n",
    "    return sorted(labels, key=lambda x: int(x.split('_')[-1]))\n",
    "\n",
    "def trimmed_mean(values: np.ndarray, trim: float = 0.2) -> float:\n",
    "    values = np.sort(np.asarray(values, dtype=float))\n",
    "    n = values.size\n",
    "    k = int(np.floor(trim * n))\n",
    "    if n - 2 * k <= 0:\n",
    "        raise ValueError('Not enough observations after trimming')\n",
    "    return values[k:n-k].mean()\n",
    "\n",
    "amounts_total = amounts[amounts['form'] == 'total'].merge(truth[['sample_id', 'treatment']], on='sample_id', how='left')\n",
    "trimmed_totals = []\n",
    "for treatment, group in amounts_total.groupby('treatment'):\n",
    "    trimmed_totals.append({'dose': int(treatment.split('_')[-1]), 'treatment': treatment, 'chrom_total_mg_per_gDW': trimmed_mean(group['amount_mg_per_gDW'].to_numpy(), trim=0.2)})\n",
    "trimmed_totals = pd.DataFrame(trimmed_totals).sort_values('dose')\n",
    "trimmed_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = group_sigma.merge(trimmed_totals[['dose', 'chrom_total_mg_per_gDW']], on='dose', how='inner')\n",
    "sigmas
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Linear Models (remove dose_1)\n",
    "We fit simple linear regressions for each window after removing the control dose. Record slope, intercept, R², RMSE, and r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_mapping(df: pd.DataFrame, feature: str) -> dict[str, float]:\n",
    "    mask = df['dose'] != 1\n",
    "    x = df.loc[mask, feature].to_numpy().reshape(-1, 1)\n",
    "    y = df.loc[mask, 'chrom_total_mg_per_gDW'].to_numpy()\n",
    "    model = LinearRegression().fit(x, y)\n",
    "    preds = model.predict(x)\n",
    "    residuals = y - preds\n",
    "    rmse = float(np.sqrt(np.mean(residuals ** 2)))\n",
    "    r = float(np.corrcoef(x.squeeze(), y)[0, 1])\n",
    "    return {\n",
    "        'feature': feature,\n",
    "        'intercept': float(model.intercept_),\n",
    "        'slope': float(model.coef_[0]),\n",
    "        'r_squared': float(model.score(x, y)),\n",
    "        'rmse': rmse,\n",
    "        'r': r,\n",
    "        'model': model,\n",
    "    }\n",
    "\n",
    "fits = [fit_mapping(sigmas, feature) for feature in ['occ_320_480', 'occ_360_410']]\n",
    "pd.DataFrame([{k: v for k, v in fit.items() if k != 'model'} for fit in fits])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the 320–480 window matches the thesis values (slope ≈ −6.11, intercept ≈ 1.076, R² ≈ 0.83)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_320 = next(f for f in fits if f['feature'] == 'occ_320_480')\n",
    "fit_320['slope'], fit_320['intercept'], fit_320['r_squared'], fit_320['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Overlay\n",
    "Visualise occupancy vs Chrom_total with the fitted line (excluding dose 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = sigmas['dose'] != 1\n",
    "x = sigmas.loc[mask, 'occ_320_480'].to_numpy().reshape(-1, 1)\n",
    "y = sigmas.loc[mask, 'chrom_total_mg_per_gDW'].to_numpy()\n",
    "model = fit_320['model']\n",
    "x_range = np.linspace(x.min(), x.max(), 100).reshape(-1, 1)\n",
    "y_pred = model.predict(x_range)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(sigmas['occ_320_480'], sigmas['chrom_total_mg_per_gDW'], color='grey', label='All doses')\n",
    "plt.scatter(x, y, color='tab:blue', label='Fit (dose≠1)')\n",
    "plt.plot(x_range, y_pred, color='black', label='Linear fit')\n",
    "plt.xlabel('Σ occupancy (320–480 nm)')\n",
    "plt.ylabel('Chrom_total (mg·gDW⁻¹)')\n",
    "plt.title('Σ occupancy → Chrom_total')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Utility\n",
    "Define a helper that takes a denoised spectrum (numpy array) and returns the predicted Chrom_total \n",
    "using the 320–480 nm model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_chrom_total(spectrum: np.ndarray, wavelengths: np.ndarray) -> float:\n",
    "    mask = (wavelengths >= 320) & (wavelengths <= 480)\n",
    "    occ = occupancy_ratio(spectrum[mask], wavelengths[mask])\n",
    "    return float(fit_320['model'].intercept_ + fit_320['model'].coef_[0] * occ)\n",
    "\n",
    "test_signal = denoised.iloc[0][wavelength_cols].to_numpy(dtype=float)\n",
    "predict_chrom_total(test_signal, numeric_wavelengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceptance Checklist\n",
    "- Slope/intercept/R² for 320–480 nm within thesis tolerances.\n",
    "- Dose ordering preserved (occupancy decreases as dose increases beyond dose 2).\n",
    "- Prediction utility ready for downstream use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
